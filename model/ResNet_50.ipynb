{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet-50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS2IOlH3aKZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow-gpu==2.1.0rc0 tensorflow==2.1.0rc0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugzzDhrzSrWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50e6129b-bde6-4481-a921-d5c1bc37753e"
      },
      "source": [
        " %tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAiLPXWcfJFu",
        "colab_type": "code",
        "outputId": "0d987ea2-db5c-4beb-c308-30d16143554e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "\n",
        "#tf.config.experimental_run_functions_eagerly(True)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Dk7kXUkrYw",
        "colab_type": "code",
        "outputId": "5a1974b5-a5b3-49a9-d825-15e6913efcc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount the google drive folder with the data\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hViNMvax20dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paths of the data\n",
        "DATASET_PATH    = '/content/drive/My Drive/retina_images/'\n",
        "CHECKPOINT_PATH = DATASET_PATH + '/checkpoints/'\n",
        "DATA_SRC_PATH   = DATASET_PATH + '/data/'\n",
        "\n",
        "TEMP_PATH       = '/content/'\n",
        "DATA_PATH       = TEMP_PATH + '/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGr0KIVHkvUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip the .zip files to the local /content/data of the notebook\n",
        "!unzip -q -n -d '{DATA_PATH}' '{DATASET_PATH+\"/train_dst.zip\"}'\n",
        "!unzip -q -n -d '{DATA_PATH}' '{DATASET_PATH+\"/test_dst.zip\"}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_5aYvyLkvfA",
        "colab_type": "code",
        "outputId": "bfbed0c5-c98e-45ef-c13f-4278599c30ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!dir '{DATA_PATH}/train_dst' | head\n",
        "!dir '{DATA_PATH}/test_dst' | head"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10003_left.jpeg   19968_left.jpeg   30000_left.jpeg   39972_right.jpeg\n",
            "10003_right.jpeg  19968_right.jpeg  30000_right.jpeg  39975_left.jpeg\n",
            "10007_left.jpeg   19970_left.jpeg   30004_left.jpeg   39975_right.jpeg\n",
            "10007_right.jpeg  19970_right.jpeg  30004_right.jpeg  39978_left.jpeg\n",
            "10009_left.jpeg   19972_left.jpeg   3000_left.jpeg    39978_right.jpeg\n",
            "10009_right.jpeg  19972_right.jpeg  3000_right.jpeg   39981_left.jpeg\n",
            "1000_left.jpeg\t  19975_left.jpeg   30012_left.jpeg   39981_right.jpeg\n",
            "1000_right.jpeg   19975_right.jpeg  30012_right.jpeg  39982_left.jpeg\n",
            "10010_left.jpeg   19976_left.jpeg   30015_left.jpeg   39982_right.jpeg\n",
            "10010_right.jpeg  19976_right.jpeg  30015_right.jpeg  39983_left.jpeg\n",
            "10000_left.jpeg   19996_right.jpeg  29928_right.jpeg  39921_right.jpeg\n",
            "10000_right.jpeg  19997_left.jpeg   29930_left.jpeg   39922_left.jpeg\n",
            "10001_left.jpeg   19997_right.jpeg  29930_right.jpeg  39922_right.jpeg\n",
            "10001_right.jpeg  19998_left.jpeg   29931_left.jpeg   39923_left.jpeg\n",
            "10002_right.jpeg  19998_right.jpeg  29931_right.jpeg  39923_right.jpeg\n",
            "10004_left.jpeg   19999_left.jpeg   29932_left.jpeg   39925_left.jpeg\n",
            "10004_right.jpeg  19999_right.jpeg  29932_right.jpeg  39925_right.jpeg\n",
            "10005_left.jpeg   1_left.jpeg\t    29934_left.jpeg   39927_left.jpeg\n",
            "10005_right.jpeg  1_right.jpeg\t    29934_right.jpeg  39927_right.jpeg\n",
            "10006_left.jpeg   20000_left.jpeg   29936_left.jpeg   39928_left.jpeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sua7Dxkmcu2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!apt-get install libimage-size-perl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upqEsJYlJdJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!imgsize '/content/data/train_dst/10003_left.jpeg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vj4dDYfNo3v",
        "colab_type": "code",
        "outputId": "86fa74c1-7965-491c-a10f-5c8197030fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!curl https://raw.githubusercontent.com/tensorflow/addons/5f9f36c03a5b132da4fe447dfa9df472ab7ea0df/tensorflow_addons/metrics/cohens_kappa.py -O"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  7223  100  7223    0     0  16876      0 --:--:-- --:--:-- --:--:-- 16876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOb8m4YyNp4o",
        "colab_type": "code",
        "outputId": "920662a5-3884-4e7b-8fb2-8783dc66f7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile cohens_kappa_fix.patch\n",
        "--- cohens_kappa.py\t2019-12-30 19:47:55.000745582 +0100\n",
        "+++ cohens_kappa_fix.py\t2019-12-30 19:50:25.117155527 +0100\n",
        "@@ -115,9 +115,10 @@\n",
        "         y_true = tf.cast(y_true, dtype=tf.int64)\n",
        "         y_pred = tf.cast(y_pred, dtype=tf.int64)\n",
        " \n",
        "-        if y_true.shape != y_pred.shape:\n",
        "-            raise ValueError(\n",
        "-                \"Number of samples in `y_true` and `y_pred` are different\")\n",
        "+        tf.debugging.assert_equal(\n",
        "+            tf.shape(y_true),\n",
        "+            tf.shape(y_pred),\n",
        "+            message=\"Number of samples in `y_true` and `y_pred` are different\")\n",
        " \n",
        "         # compute the new values of the confusion matrix\n",
        "         new_conf_mtx = tf.math.confusion_matrix("
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting cohens_kappa_fix.patch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhzuI6vFOT6p",
        "colab_type": "code",
        "outputId": "5c4e4492-f002-440e-9f0a-b6de0a212eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo \"\" >> cohens_kappa_fix.patch\n",
        "!patch cohens_kappa.py < cohens_kappa_fix.patch"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patching file cohens_kappa.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGcpmwYkOV5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run -i cohens_kappa.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyCArTJB947T",
        "colab_type": "text"
      },
      "source": [
        "# ResNet-50 architecture\n",
        "### Identity Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GZKt3pusexbj",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# Build the identity block\n",
        "class IdentityBlock():\n",
        "  def __init__(self, kernel_size, filters, name, **kwargs):\n",
        "    '''\n",
        "      kernel_size: (tuple) size of the filter (kernel)\n",
        "      filters: number of filters (kernels)\n",
        "      name: base name for the block\n",
        "    '''\n",
        "\n",
        "    self.kernel_size = kernel_size\n",
        "    self.filters = filters\n",
        "    self.expansion = 4\n",
        "    self.name = name\n",
        "\n",
        "    self.__build()\n",
        "  \n",
        "  def __build(self):\n",
        "    base_name = 'conv'+str(self.name['layer'])+'_block'+str(self.name['inner'])+'_'\n",
        "\n",
        "    self.conv1 = layers.Conv2D(self.filters, (1, 1), name=base_name+'1_conv')\n",
        "    self.bn1 = layers.BatchNormalization(name=base_name+'1_bn')\n",
        "    self.relu1 = layers.Activation('relu', name='activation_'+str(self.name['activation']))\n",
        "\n",
        "    self.conv2 = layers.Conv2D(self.filters, self.kernel_size, padding='same', name=base_name+'2_conv')\n",
        "    self.bn2 = layers.BatchNormalization(name=base_name+'2_bn')\n",
        "    self.relu2 = layers.Activation('relu', name='activation_'+str(self.name['activation'] + 1))\n",
        "\n",
        "    self.conv3 = layers.Conv2D(self.filters*self.expansion, (1, 1), name=base_name+'3_conv')\n",
        "    self.bn3 = layers.BatchNormalization(name=base_name+'3_bn')\n",
        "    self.relu3 = layers.Activation('relu', name='activation_'+str(self.name['activation'] + 2))\n",
        "\n",
        "\n",
        "  def __call__(self, input_tensor):\n",
        "    x = self.conv1(input_tensor)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor], name=self.name['merge'])\n",
        "    return self.relu3(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0axcqaS-AiH",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Block\n",
        "\n",
        "Expands the input depth through a 1x1 convolution to allow the addition with the output of the block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uOMc761uE5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the conv block\n",
        "class ConvBlock():\n",
        "  def __init__(self, kernel_size, filters, name, strides=(2, 2), **kwargs):\n",
        "    '''\n",
        "      kernel_size: (tuple) size of the filter (kernel)\n",
        "      filters: number of filters (kernels)\n",
        "      name: base name for the block\n",
        "      strides: (tuple) with the size of the stride \n",
        "    '''\n",
        "\n",
        "    self.kernel_size = kernel_size\n",
        "    self.filters = filters\n",
        "    self.strides = strides\n",
        "    self.expansion = 4\n",
        "    self.name = name\n",
        "    self.__build()\n",
        "\n",
        "\n",
        "  def __build(self):\n",
        "    base_name = 'conv'+str(self.name['layer'])+'_block'+str(self.name['inner'])+'_'\n",
        "\n",
        "    self.conv1 = layers.Conv2D(self.filters, (1, 1), strides=self.strides, name=base_name+'1_conv')\n",
        "    self.bn1 = layers.BatchNormalization(name=base_name+'1_bn')\n",
        "    self.relu1 = layers.Activation('relu', name='activation_'+str(self.name['activation']))\n",
        "\n",
        "    self.conv2 = layers.Conv2D(self.filters, self.kernel_size, padding='same', name=base_name+'2_conv')\n",
        "    self.bn2 = layers.BatchNormalization(name=base_name+'2_bn')\n",
        "    self.relu2 = layers.Activation('relu', name='activation_'+str(self.name['activation'] + 1))\n",
        "\n",
        "    self.conv3 = layers.Conv2D(self.filters*self.expansion, (1, 1), name=base_name+'3_conv')\n",
        "    self.bn3 = layers.BatchNormalization(name=base_name+'3_bn')\n",
        "    self.relu3 = layers.Activation('relu', name='activation_'+str(self.name['activation'] + 2))\n",
        "\n",
        "    self.shortcut_conv = layers.Conv2D(self.filters*self.expansion, (1, 1), strides=self.strides, name=base_name+'0_conv')\n",
        "    self.shortcut_bn = layers.BatchNormalization(name=base_name+'0_bn')\n",
        "\n",
        "\n",
        "  def __call__(self, input_tensor):\n",
        "    x = self.conv1(input_tensor)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    shortcut = self.shortcut_conv(input_tensor)\n",
        "    shortcut = self.shortcut_bn(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut], name=self.name['merge'])\n",
        "    return self.relu3(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r63sqVDZ-pnd",
        "colab_type": "text"
      },
      "source": [
        "## Build the full network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jrCyAEDmpE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the ResNet\n",
        "class ResNet():\n",
        "  def __init__(self, classes=5):\n",
        "    '''\n",
        "      classes: number of output classes\n",
        "    '''\n",
        "    \n",
        "    self._layers = []\n",
        "    self.classes = classes\n",
        "    \n",
        "    # According to paper (ResNet-50)\n",
        "    self.n_layers = [3, 4, 6, 3]\n",
        "    self.filters = 64\n",
        "\n",
        "  def __build(self):\n",
        "    filters = [64, 128, 256, 512]\n",
        "    \n",
        "    # for naming purposes\n",
        "    merge = 1\n",
        "    activation = 2\n",
        "    \n",
        "    # head\n",
        "    self._layers.append(layers.ZeroPadding2D(padding=(3, 3), name='head_padding1'))\n",
        "    self._layers.append(layers.Conv2D(self.filters, (7, 7), strides=(2, 2), padding='valid', name='conv1_conv'))\n",
        "    self._layers.append(layers.BatchNormalization(name='conv1_bn'))\n",
        "    self._layers.append(layers.Activation('relu', name='activation_1'))\n",
        "    self._layers.append(layers.ZeroPadding2D(padding=(1, 1), name='head_padding2'))\n",
        "    self._layers.append(layers.MaxPooling2D((3, 3), strides=(2, 2), name='maxpooling'))\n",
        "\n",
        "    # blocks\n",
        "    for i, l in enumerate(self.n_layers):\n",
        "      for j in range(l):\n",
        "        name = {\n",
        "            'layer': i+2,\n",
        "            'inner': j+1,\n",
        "            'merge': 'merge_'+str(merge),\n",
        "            'activation': activation\n",
        "        }\n",
        "\n",
        "        if i == 0 and j == 0:\n",
        "          self._layers.append(ConvBlock((3, 3), filters[i], strides=(1, 1), name=name))\n",
        "        elif j == 0:\n",
        "          self._layers.append(ConvBlock((3, 3), filters[i], name=name))\n",
        "        else:\n",
        "          self._layers.append(IdentityBlock((3, 3), filters[i], name=name))\n",
        "        \n",
        "        merge += 1\n",
        "        activation +=3\n",
        "\n",
        "    self._layers.append(layers.GlobalAveragePooling2D(name='avg_pool'))\n",
        "    # self._layers.append(layers.Dense(self.classes, activation='softmax', name='fc'))\n",
        "\n",
        "  def __call__(self, input_tensor):\n",
        "    self.__build()\n",
        "\n",
        "    for i, _layer in enumerate(self._layers):\n",
        "      if i == 0:\n",
        "        x = _layer(input_tensor)\n",
        "      else:\n",
        "        x = _layer(x)\n",
        "\n",
        "    return keras.Model(input_tensor, x, name='resnet-50')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQSeitc2IxS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to load the pretrained weights onto the custom model\n",
        "def transfer_weights(model):\n",
        "  '''\n",
        "    model: keras model to transfer the weights (must be resnet-50)\n",
        "  '''\n",
        "  trained = keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=model.input.shape, pooling='avg', classes=5)\n",
        "\n",
        "  for i, layer in enumerate(trained.layers):\n",
        "    if len(layer.weights) > 0 and layer.name is not 'probs':\n",
        "      weights = layer.get_weights()\n",
        "      model.get_layer(layer.name).set_weights(weights)\n",
        "  \n",
        "  model.save_weights('/content/drive/My Drive/retina_images/pretrained/resnet50_weights_imagenet_no_dense.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soxxxqmEsG1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generates a model for regression\n",
        "def generate_model(model=None, classes=5, shape=(512, 512, 3)):\n",
        "  '''\n",
        "    model: keras model\n",
        "    classes: number of output classes\n",
        "    shape: tuple like shape of the input\n",
        "  '''\n",
        "  \n",
        "  input = keras.Input(shape=shape)\n",
        "  \n",
        "  if model is None:\n",
        "    model = ResNet(classes=classes)(input)\n",
        "\n",
        "  x = layers.Dense(1, activation='linear')(model.output)\n",
        "\n",
        "  return keras.Model(model.input, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdK27mFYU05N",
        "colab_type": "code",
        "outputId": "d60515cf-2eff-40d1-93b4-22b6a4a5cb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Display model layers\n",
        "#model = ResNet(classes=5)(keras.Input(shape=(384, 384, 3)))\n",
        "# model = keras.applications.resnet.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
        "#transfer_weights(model)\n",
        "#model.load_weights(f'{DATASET_PATH}pretrained/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "# model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 384, 384, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCLtfuABAP2R",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiOpJhxiMTpC",
        "colab_type": "code",
        "outputId": "c8bdf382-4fad-411a-84c7-4c6db01a024a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_labels = pd.read_csv(f'{DATASET_PATH}train_labels.csv')\n",
        "test_labels = pd.read_csv(f'{DATASET_PATH}test_labels.csv')\n",
        "\n",
        "classes = [0, 1, 2, 3, 4]\n",
        "\n",
        "# Remove usage column\n",
        "test_labels = test_labels.drop('Usage', axis=1)\n",
        "\n",
        "train_labels['image'] = train_labels['image'].apply(lambda f: f'train_dst/{f}.jpeg')\n",
        "test_labels['image'] = test_labels['image'].apply(lambda f: f'test_dst/{f}.jpeg')\n",
        "\n",
        "data = pd.concat([train_labels, test_labels]).sample(frac=1, random_state=97309938)\n",
        "data = data.dropna()\n",
        "\n",
        "data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18337</th>\n",
              "      <td>train_dst/23095_right.jpeg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13617</th>\n",
              "      <td>test_dst/11328_right.jpeg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15616</th>\n",
              "      <td>test_dst/12957_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32626</th>\n",
              "      <td>test_dst/27055_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9066</th>\n",
              "      <td>train_dst/11378_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42352</th>\n",
              "      <td>test_dst/35006_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31559</th>\n",
              "      <td>test_dst/26161_right.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35946</th>\n",
              "      <td>test_dst/29747_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10115</th>\n",
              "      <td>train_dst/12739_right.jpeg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30189</th>\n",
              "      <td>train_dst/38189_right.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88702 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image  level\n",
              "18337  train_dst/23095_right.jpeg      3\n",
              "13617   test_dst/11328_right.jpeg      2\n",
              "15616    test_dst/12957_left.jpeg      0\n",
              "32626    test_dst/27055_left.jpeg      0\n",
              "9066    train_dst/11378_left.jpeg      0\n",
              "...                           ...    ...\n",
              "42352    test_dst/35006_left.jpeg      0\n",
              "31559   test_dst/26161_right.jpeg      0\n",
              "35946    test_dst/29747_left.jpeg      0\n",
              "10115  train_dst/12739_right.jpeg      2\n",
              "30189  train_dst/38189_right.jpeg      1\n",
              "\n",
              "[88702 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jipVpIqrA4z_",
        "colab_type": "text"
      },
      "source": [
        "### Visualization of the number of data per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8Zge4DgTna",
        "colab_type": "code",
        "outputId": "9e2ecaec-f932-4fc1-cd5f-64cc1de5068b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "plt.hist(x=data['level'])\n",
        "plt.xticks(classes)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7f3edda63b38>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edda63eb8>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edda63c88>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edd7f0828>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edd7f0dd8>],\n",
              " <a list of 5 Text xticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuIcYGcQp2Xx",
        "colab_type": "text"
      },
      "source": [
        "# Normal training split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqZgHRuegXE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split = int(len(data) * 0.15)\n",
        "test_df = data.iloc[:split].copy().reset_index(drop=True)\n",
        "train_df = data.iloc[split:].copy()\n",
        "\n",
        "train_c0 = train_df[train_df['level'] == 0]\n",
        "train_c0 = train_c0.iloc[:int(len(train_c0)*0.25)]\n",
        "train_cP = train_df[train_df['level'] > 0]\n",
        "\n",
        "train_df = pd.concat([train_c0, train_cP]).sample(frac=1, random_state=69859680).reset_index(drop=True) # concat & shuffle data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaVoU9LFqBdo",
        "colab_type": "text"
      },
      "source": [
        "# High definition training split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT0mjOb5jv1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# newdata = None\n",
        "\n",
        "# for class_ in classes:\n",
        "#   values = data.where(data['level'] == class_).dropna() \n",
        "#   if class_ == 0:\n",
        "#     newdata = values.iloc[:int(len(values) * 0.05)]\n",
        "#   else:\n",
        "#     newdata = pd.concat([newdata, values.iloc[:int(len(values) * 0.2)]])\n",
        "\n",
        "# split = int(len(newdata) * 0.1)\n",
        "# test_df = newdata.iloc[:split].copy()\n",
        "# train_df = newdata.iloc[split:].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMpd9WiHBHF-",
        "colab_type": "text"
      },
      "source": [
        "### New distribution for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_CvXK7uKzK",
        "colab_type": "code",
        "outputId": "2797dacf-117d-419d-8cbc-6e86b45985d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "plt.hist(x=train_df['level'])\n",
        "plt.xticks(classes)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7f3edd53db38>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edd53d7f0>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edd53d048>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edcd8c630>,\n",
              "  <matplotlib.axis.XTick at 0x7f3edcd8cc18>],\n",
              " <a list of 5 Text xticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4xcvYH4LBbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " aug_seq = iaa.Sequential([\n",
        "  iaa.Fliplr(0.5),\n",
        "  iaa.Flipud(0.5),\n",
        "  iaa.Sequential([\n",
        "    iaa.Affine(rotate=(0, 360)),\n",
        "    iaa.Sometimes(0.5, iaa.Crop(percent=(0.01, 0.1), sample_independently=False)), # crop image equally on both sides\n",
        "  ]),\n",
        "  iaa.Multiply((0.9, 1.5)),\n",
        "], random_order=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26SDWCTRvyn0",
        "colab_type": "code",
        "outputId": "c6ae5775-f8d0-4541-8fb5-27b5541043ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 384\n",
        " \n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda img: np.clip(aug_seq.augment_image(img) / 255.0, 0, 1))\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='image',\n",
        "    y_col='level',\n",
        "    class_mode='raw',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    directory=DATA_PATH,\n",
        "    validate_filenames=True)\n",
        "\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df.iloc[:len(test_df)//3],\n",
        "    x_col='image',\n",
        "    y_col='level',\n",
        "    class_mode='raw',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    directory=DATA_PATH,\n",
        "    validate_filenames=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 33624 validated image filenames.\n",
            "Found 4424 validated image filenames.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 76 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n",
            "/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 11 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27UfvRrSCVPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vanilla imagenet weights\n",
        "imagenet_weights = f'{DATASET_PATH}pretrained/resnet50_weights_imagenet_no_dense.h5'\n",
        "# weights of first training\n",
        "diabetic_regression_weights = f'{DATASET_PATH}checkpoints/resnet50_dense_regression.h5'\n",
        "# weights of the last training with 384x384 images\n",
        "checkpoint_path = f'{DATASET_PATH}checkpoints/resnet50_dense_regression_checkpoint_384.h5'\n",
        "# weights of las training with 512x512 images\n",
        "checkpoint_high_path = f'{DATASET_PATH}checkpoints/resnet50_dense_regression_checkpoint_512.h5'\n",
        "# last checkpoint\n",
        "last_checkpoint = f'{DATASET_PATH}checkpoints/resnet50_dense_regression_last.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq3NCI2n9ecv",
        "colab_type": "text"
      },
      "source": [
        "# Training for multi label classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k06gcSKFxiVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = ResNet(classes=5)(keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "# model.load_weights(imagenet_weights)\n",
        "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.CategoricalCrossentropy(), metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "# model.fit(train_generator,\n",
        "#           epochs=10,\n",
        "#           validation_data=validation_generator,\n",
        "#           max_queue_size=16,\n",
        "#           workers=4, use_multiprocessing=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jz4mtFz9j9w",
        "colab_type": "text"
      },
      "source": [
        "# Training for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TZUMTkhsnIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HistoryLogger(keras.callbacks.Callback):\n",
        "  def __init__(self, prefix):\n",
        "    super(HistoryLogger, self).__init__()\n",
        "\n",
        "    self.prefix = prefix\n",
        "    self.history = {}\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs={}):\n",
        "    self.history = {}\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    df = pd.DataFrame.from_dict(self.history)\n",
        "    df.to_hdf(f'{DATASET_PATH}/history/{self.prefix}.hdf5', key=f'E{epoch}', mode='a')\n",
        "\n",
        "    hist = {}\n",
        "    for k, v in logs.items():\n",
        "      hist.setdefault(k, []).append(v)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(hist)\n",
        "    df.to_hdf(f'{DATASET_PATH}/history/{self.prefix}.hdf5', key=f'VAL_E{epoch}', mode='a')\n",
        "\n",
        "  def on_batch_end(self, batch, logs={}):\n",
        "    for k, v in logs.items():\n",
        "      self.history.setdefault(k, []).append(v)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch, alpha):\n",
        "  decay = (1 - (epoch / float(10))) ** 1\n",
        "  alpha = 0.00001 * decay\n",
        "\n",
        "  return float(alpha)\n",
        "\n",
        "class KappaMetric(CohenKappa):\n",
        "    def __init__(self):\n",
        "      super().__init__(num_classes=5, weightage='quadratic')\n",
        "\n",
        "    @staticmethod\n",
        "    def classify(x):\n",
        "      return tf.case(\n",
        "          [(tf.less(x, 0.5), lambda: 0.0),\n",
        "           (tf.less(x, 1.5), lambda: 1.0),\n",
        "           (tf.less(x, 2.5), lambda: 2.0),\n",
        "           (tf.less(x, 3.5), lambda: 3.0)],\n",
        "          default=lambda: 4.0, exclusive=False)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "      t = tf.reshape(y_true, shape=[-1])\n",
        "      p = tf.map_fn(KappaMetric.classify, y_pred)\n",
        "      \n",
        "      super().update_state(t, p, sample_weight)\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(f'{DATASET_PATH}checkpoints/resnet50_dense_regression_last.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
        "hs_callback = HistoryLogger(f'from_imagenet_keras_history_full')\n",
        "\n",
        "model = ResNet(classes=5)(keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "model = generate_model(model, 5, (IMG_SIZE, IMG_SIZE, 3))\n",
        "model.load_weights(last_checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl8pUomNtJu6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "c61987a2-a74c-4175-b524-902d457ac5ac"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001), loss='mse', metrics=['mae', 'accuracy', KappaMetric()])\n",
        "model.fit(train_generator,\n",
        "          epochs=30,\n",
        "          initial_epoch=6,\n",
        "          validation_data=validation_generator,\n",
        "          callbacks=[checkpoint, hs_callback],\n",
        "          max_queue_size=16,\n",
        "          workers=4, use_multiprocessing=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 1051 steps, validate for 139 steps\n",
            "Epoch 7/30\n",
            "1050/1051 [============================>.] - ETA: 0s - loss: 0.5886 - mae: 0.6149 - accuracy: 0.3106 - cohen_kappa: 0.6963\n",
            "Epoch 00007: val_loss improved from inf to 0.46463, saving model to /content/drive/My Drive/retina_images/checkpoints/resnet50_dense_regression_last.h5\n",
            "1051/1051 [==============================] - 613s 583ms/step - loss: 0.5884 - mae: 0.6147 - accuracy: 0.3107 - cohen_kappa: 0.6965 - val_loss: 0.4646 - val_mae: 0.5253 - val_accuracy: 0.5124 - val_cohen_kappa: 0.6655\n",
            "Epoch 8/30\n",
            " 879/1051 [========================>.....] - ETA: 1:26 - loss: 0.5644 - mae: 0.6006 - accuracy: 0.3191 - cohen_kappa: 0.7099"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXz6r6YAyR7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4e829509-b27d-49d6-ec40-cc2fcc48f8b7"
      },
      "source": [
        "test_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='image',\n",
        "    y_col='level',\n",
        "    class_mode='raw',\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE*2,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    directory=DATA_PATH,\n",
        "    validate_filenames=True)\n",
        "\n",
        "def classify(x):\n",
        "  if x < 0.5:\n",
        "      return 0\n",
        "  elif x < 1.5:\n",
        "      return 1\n",
        "  elif x < 2.5:\n",
        "      return 2\n",
        "  elif x < 3.5:\n",
        "      return 3\n",
        "  return 4\n",
        "\n",
        "#model = create_model(img_size=300)\n",
        "#model.load_weights(fname)\n",
        "\n",
        "progbar = tf.keras.utils.Progbar(len(test_generator))\n",
        "\n",
        "y_predicted, y_true = [], []\n",
        "for i in range(len(test_generator)):\n",
        "  x, true_y = test_generator[i]\n",
        "  predictions = model.predict(x, workers=2)\n",
        "\n",
        "  del x\n",
        "\n",
        "  for j in range(len(predictions)):\n",
        "    y_predicted.append(int(classify(predictions[j])))\n",
        "    y_true.append(int(true_y[j]))\n",
        "  \n",
        "  progbar.update(i)\n",
        "\n",
        "# np.set_printoptions(precision=4, suppress=True)\n",
        "# print(confusion_matrix.astype(float) / confusion_matrix.sum(axis=1)[:, np.newaxis])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 29 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 13276 validated image filenames.\n",
            "207/208 [============================>.] - ETA: 1s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGjBp5vpxk9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "b63348d9-2ca7-4f77-ee81-80d916c0c85e"
      },
      "source": [
        "confusion_matrix = np.zeros((5, 5))\n",
        "\n",
        "for i in range(len(y_predicted)):\n",
        "  confusion_matrix[y_true[i], y_predicted[i]] += 1\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 9))\n",
        "ax.imshow(confusion_matrix.astype(float) / confusion_matrix.sum(axis=1)[:, np.newaxis], cmap = plt.cm.Blues, vmax=1.0, vmin=0.0)\n",
        "ax.set_xlabel('predicted class')\n",
        "ax.set_ylabel('true class')\n",
        "fig.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAIWCAYAAADtbg+XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1phEw7I6GJja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "5b880250-7e2d-41ca-f5cd-159ea2f6081b"
      },
      "source": [
        "hist = pd.DataFrame({'cohen_kappa' : []})\n",
        "fig, ax = plt.subplots()\n",
        "for i in range(2):\n",
        "  #try:\n",
        "    key = f'E{i}'\n",
        "    history_df = pd.read_hdf(f'{DATASET_PATH}/history/copy_from_imagenet_history_full.hdf5', key=key)\n",
        "\n",
        "    #ax.plot(history_df['batch'], history_df['cohen_kappa'], label=key)\n",
        "    hist = pd.concat([hist, history_df], ignore_index=True)\n",
        "  #except:\n",
        "    #None\n",
        "\n",
        "#ax.plot(np.arange(hist.shape[0]), hist['cohen_kappa'], label='cohen_kappa')\n",
        "#ax.legend()\n",
        "#fig.show()\n",
        "print(hist['cohen_kappa'][40:20])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40     0.000000\n",
            "41     0.000000\n",
            "42     0.000000\n",
            "43     0.000000\n",
            "44     0.000000\n",
            "         ...   \n",
            "195    0.085766\n",
            "196    0.085875\n",
            "197    0.085783\n",
            "198    0.086498\n",
            "199    0.086462\n",
            "Name: cohen_kappa, Length: 160, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "cohens_kappa.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  # Unless required by applicable law or agreed to in writing, software\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uz9rGdm9rw3",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89SmUxvde0sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(x):\n",
        "  if x <= 0.8:\n",
        "    return 0\n",
        "  elif x > 0.8 and x <= 1.6:\n",
        "    return 1\n",
        "  elif x > 1.6 and x <= 2.4:\n",
        "    return 2\n",
        "  elif x > 2.4 and x <= 3.2:\n",
        "    return 3\n",
        "  elif x > 3.2:\n",
        "    return 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSuLR4rxl07M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify05(x):\n",
        "  if x < 0.5:\n",
        "      return 0\n",
        "  elif x < 1.5:\n",
        "      return 1\n",
        "  elif x < 2.5:\n",
        "      return 2\n",
        "  elif x < 3.5:\n",
        "      return 3\n",
        "  return 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_jdDDRaY0Nv",
        "colab_type": "code",
        "outputId": "4f2d7b48-10d9-4b7d-8f1d-681fc8a95c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='image',\n",
        "    y_col='level',\n",
        "    class_mode='raw',\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE*2,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    directory=DATA_PATH,\n",
        "    validate_filenames=True)\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "progress = keras.utils.Progbar(target=len(validation_generator))\n",
        "\n",
        "for i in range(len(validation_generator)):\n",
        "  x, true_y = validation_generator[i]\n",
        "  _predictions = model.predict(x)\n",
        "\n",
        "  del x\n",
        "\n",
        "  for j in range(len(_predictions)):\n",
        "    class_p = int(classify05(_predictions[j]))\n",
        "    class_t = int(true_y[j])\n",
        "    predictions.append(class_p)\n",
        "    true_labels.append(class_t)\n",
        "  \n",
        "  progress.update(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 29 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 13276 validated image filenames.\n",
            "1659/1660 [============================>.] - ETA: 0s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwJoNwrefzIJ",
        "colab_type": "code",
        "outputId": "06b2ce86-b520-4228-c54e-e50323278435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sklearn.metrics\n",
        "\n",
        "sklearn.metrics.accuracy_score(true_labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7019433564326605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}